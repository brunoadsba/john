# DocumentaÃ§Ã£o Completa: Sistema de Ãudio - Jonh Assistant

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura do Sistema de Ãudio](#arquitetura-do-sistema-de-Ã¡udio)
3. [Fluxo Completo de Ãudio](#fluxo-completo-de-Ã¡udio)
4. [Mobile: GravaÃ§Ã£o e Envio](#mobile-gravaÃ§Ã£o-e-envio)
5. [Backend: RecepÃ§Ã£o e Processamento](#backend-recepÃ§Ã£o-e-processamento)
6. [Backend: STT (Speech-to-Text)](#backend-stt-speech-to-text)
7. [Backend: LLM (GeraÃ§Ã£o de Resposta)](#backend-llm-geraÃ§Ã£o-de-resposta)
8. [Backend: TTS (Text-to-Speech)](#backend-tts-text-to-speech)
9. [Backend: Retorno de Ãudio](#backend-retorno-de-Ã¡udio)
10. [Mobile: RecepÃ§Ã£o e ReproduÃ§Ã£o](#mobile-recepÃ§Ã£o-e-reproduÃ§Ã£o)
11. [ConfiguraÃ§Ãµes de Ãudio](#configuraÃ§Ãµes-de-Ã¡udio)
12. [Troubleshooting: Ãudio Enviado Mas Sem Resposta](#troubleshooting-Ã¡udio-enviado-mas-sem-resposta)

---

## VisÃ£o Geral

O sistema de Ã¡udio do Jonh Assistant implementa um pipeline completo de processamento de voz:
1. **GravaÃ§Ã£o** (Mobile) â†’ Ãudio WAV 16kHz mono
2. **TransmissÃ£o** (WebSocket) â†’ Bytes binÃ¡rios
3. **TranscriÃ§Ã£o** (Backend - Whisper) â†’ Texto
4. **Processamento** (Backend - LLM) â†’ Resposta em texto
5. **SÃ­ntese** (Backend - Piper TTS) â†’ Ãudio WAV
6. **TransmissÃ£o** (WebSocket) â†’ Bytes binÃ¡rios
7. **ReproduÃ§Ã£o** (Mobile) â†’ Ãudio tocado

---

## Arquitetura do Sistema de Ãudio

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MOBILE APP (Flutter)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ VoiceButton  â”‚â”€â”€â”€â–¶â”‚ AudioService â”‚â”€â”€â”€â–¶â”‚ ApiService   â”‚     â”‚
â”‚  â”‚  (UI Widget) â”‚    â”‚              â”‚    â”‚              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ AudioRecord  â”‚    â”‚ WebSocket    â”‚     â”‚
â”‚                      â”‚ AudioPlaybackâ”‚    â”‚ Client       â”‚     â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                  â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚ WebSocket
                                                   â”‚ (ws://.../ws/listen)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (FastAPI)              â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚             â”‚
â”‚  â”‚ WebSocket    â”‚â”€â”€â”€â–¶â”‚ WebSocket    â”‚          â”‚             â”‚
â”‚  â”‚ /ws/listen   â”‚    â”‚ Handler      â”‚          â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚             â”‚
â”‚                              â”‚                  â”‚             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚             â”‚
â”‚                    â”‚                    â”‚       â”‚             â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”â”‚             â”‚
â”‚            â”‚ process_audio â”‚   â”‚ handle_audio â”‚â”‚             â”‚
â”‚            â”‚ _complete     â”‚   â”‚ _data        â”‚â”‚             â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚             â”‚
â”‚                    â”‚                    â”‚       â”‚             â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚       â”‚             â”‚
â”‚         â”‚                     â”‚        â”‚       â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”    â”‚       â”‚             â”‚
â”‚  â”‚ WhisperSTT  â”‚    â”‚  PiperTTS  â”‚    â”‚       â”‚             â”‚
â”‚  â”‚   Service   â”‚    â”‚   Service  â”‚    â”‚       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â”‚       â”‚             â”‚
â”‚         â”‚                  â”‚          â”‚       â”‚             â”‚
â”‚         â”‚ STT: Audio â†’ Text           â”‚       â”‚             â”‚
â”‚         â”‚                  â”‚          â”‚       â”‚             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”‚       â”‚             â”‚
â”‚  â”‚     LLM Service (Groq/Ollama)  â”‚  â”‚       â”‚             â”‚
â”‚  â”‚     Text â†’ Response            â”‚  â”‚       â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚       â”‚             â”‚
â”‚                                       â”‚       â”‚             â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                              â”‚                              â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                      â”‚ safe_send_bytesâ”‚                      â”‚
â”‚                      â”‚ (WebSocket)    â”‚                      â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Fluxo Completo de Ãudio

### 1. Mobile: GravaÃ§Ã£o e Envio

**Arquivo:** `mobile_app/lib/widgets/voice_button.dart`

```dart
// 1. UsuÃ¡rio pressiona botÃ£o de gravaÃ§Ã£o
await audioService.startRecording(); // AudioService.startRecording()

// 2. UsuÃ¡rio solta botÃ£o
final audioBytes = await audioService.stopRecording(); // Retorna Uint8List

// 3. Envia via WebSocket
await apiService.sendAudio(audioBytes); // ApiService.sendAudio()
```

**Arquivo:** `mobile_app/lib/services/audio/audio_recording.dart`

ConfiguraÃ§Ã£o de gravaÃ§Ã£o:
- **Formato:** WAV
- **Sample Rate:** 16000 Hz (16kHz)
- **Canais:** 1 (mono)
- **Encoder:** `AudioEncoder.wav`
- **Caminho:** `/temp/audio_{timestamp}.wav`

```dart
await _recorder.start(
  const RecordConfig(
    encoder: AudioEncoder.wav,
    sampleRate: 16000,  // â† CRÃTICO: 16kHz
    numChannels: 1,     // â† CRÃTICO: Mono
  ),
  path: path,
);
```

**Arquivo:** `mobile_app/lib/services/api_service.dart`

Envio via WebSocket:
```dart
Future<void> sendAudio(List<int> audioBytes) async {
  if (!_isConnected) {
    debugPrint('âš ï¸ WebSocket nÃ£o conectado');
    return;
  }
  
  _wsClient.send(Uint8List.fromList(audioBytes));
  debugPrint('ğŸ“¤ Ãudio enviado: ${audioBytes.length} bytes');
}
```

**Arquivo:** `mobile_app/lib/services/api/websocket_client.dart`

URL do WebSocket:
```dart
static String get wsUrl {
  final baseUrl = Env.backendUrl.isNotEmpty
      ? Env.backendUrl
      : 'http://192.168.1.5:8000';
  return baseUrl
          .replaceFirst('http://', 'ws://')
          .replaceFirst('https://', 'wss://') +
      '/ws/listen';  // â† Endpoint: /ws/listen
}
```

---

### 2. Backend: RecepÃ§Ã£o e Processamento

**Arquivo:** `backend/api/routes/websocket.py`

Endpoint WebSocket:
```python
@router.websocket("/ws/listen")
async def websocket_listen(websocket: WebSocket):
    await handle_listen_websocket(websocket, context_manager)
```

**Arquivo:** `backend/api/handlers/websocket_listen_handler.py`

Handler principal:
```python
async def handle_listen_websocket(websocket: WebSocket, context_manager):
    await websocket.accept()
    session_id = None
    
    while True:
        data = await websocket.receive()
        
        if "bytes" in data:
            # Dados de Ã¡udio recebidos
            audio_data = data["bytes"]
            session_id = await handle_audio_data(websocket, audio_data, session_id)
```

**Arquivo:** `backend/api/routes/websocket_handlers.py`

Roteamento para processamento:
```python
async def handle_audio_data(websocket, audio_data, session_id):
    return await process_audio_complete(
        websocket=websocket,
        audio_data=audio_data,  # â† Bytes do Ã¡udio
        session_id=session_id,
        stt_service=stt_service,
        llm_service=llm_service,
        tts_service=tts_service,
        context_manager=context_manager,
        memory_service=memory_service,
        plugin_manager=plugin_manager,
        web_search_tool=web_search_tool,
        feedback_service=feedback_service
    )
```

---

### 3. Backend: STT (Speech-to-Text)

**Arquivo:** `backend/api/handlers/websocket_audio_processor.py`

Processamento completo:
```python
async def process_audio_complete(...):
    # 1. Transcreve Ã¡udio
    logger.info("ğŸ™ï¸ Iniciando transcriÃ§Ã£o de Ã¡udio...")
    texto_transcrito, confianca, duracao = stt_service.transcribe_audio(audio_data)
    
    # Envia status de transcriÃ§Ã£o
    await safe_send_json(websocket, {
        "type": "processing",
        "stage": "transcribing"
    })
    
    # Envia transcriÃ§Ã£o
    await safe_send_json(websocket, {
        "type": "transcription",
        "text": texto_transcrito,
        "confidence": confianca
    })
```

**Arquivo:** `backend/services/stt_service.py`

ServiÃ§o Whisper:
```python
class WhisperSTTService:
    def __init__(
        self,
        model_size: str = "large-v3",  # â† Configurado em settings
        device: str = "cpu",
        compute_type: str = "int8"
    ):
        self.model_size = model_size
        self.device = device
        self.compute_type = compute_type
    
    def transcribe_audio(self, audio_data: bytes, language: str = "pt"):
        # Converte bytes para array numpy
        audio_array, sample_rate = self._bytes_to_audio(audio_data)
        
        # Transcreve com Whisper
        segments, info = self.model.transcribe(
            audio_array,
            language=language,
            beam_size=3,  # Otimizado para performance
            vad_filter=use_vad_optimized,  # VAD para Ã¡udios > 2s
        )
        
        texto_completo = " ".join([segment.text for segment in segments])
        return texto_completo.strip(), info.language_probability, duracao
```

**ConfiguraÃ§Ã£o (settings.py):**
```python
whisper_model: str = "large-v3"      # Modelo Whisper
whisper_device: str = "cpu"          # CPU ou CUDA
whisper_compute_type: str = "int8"   # int8, float16, float32
```

**Formato esperado pelo Whisper:**
- Sample Rate: Qualquer (Whisper converte internamente para 16kHz)
- Canais: Mono (convertido automaticamente se estÃ©reo)
- Formato: Qualquer suportado por `soundfile` (WAV, MP3, OGG, FLAC)

---

### 4. Backend: LLM (GeraÃ§Ã£o de Resposta)

**Arquivo:** `backend/api/handlers/websocket_audio_processor.py`

GeraÃ§Ã£o de resposta:
```python
    # 2. Gera resposta com LLM
    await safe_send_json(websocket, {
        "type": "processing",
        "stage": "generating"
    })
    
    await context_manager.add_message(session_id, "user", texto_transcrito)
    contexto = await context_manager.get_context(session_id)
    
    # Prepara tools e tool executor
    tools, tool_executor = prepare_tools_for_websocket(plugin_manager, web_search_tool)
    
    # Gera resposta
    resposta_texto, tokens = llm_service.generate_response(
        texto_transcrito,
        contexto,
        memorias_contexto=memoria_contexto,
        tools=tools,
        tool_executor=tool_executor
    )
    
    # Sanitiza resposta
    sanitizer = get_sanitizer()
    resposta_texto = sanitizer.sanitize(resposta_texto)
    
    await context_manager.add_message(session_id, "assistant", resposta_texto)
    
    # Envia resposta de texto
    await safe_send_json(websocket, {
        "type": "response",
        "text": resposta_texto,
        "tokens": tokens,
        "metrics": {
            "sttTime": int(stt_time),
            "llmTime": int(llm_time),
            "ttsTime": None
        }
    })
```

**Problema potencial:** Se o LLM nÃ£o retornar resposta ou retornar vazio, a mensagem `type: "response"` pode nÃ£o ser enviada ou estar vazia.

---

### 5. Backend: TTS (Text-to-Speech)

**Arquivo:** `backend/api/handlers/websocket_audio_processor.py`

SÃ­ntese de voz:
```python
    # 3. Sintetiza Ã¡udio
    await safe_send_json(websocket, {
        "type": "processing",
        "stage": "synthesizing"
    })
    
    tts_start = time.time()
    logger.info("ğŸ”Š Iniciando sÃ­ntese de voz...")
    audio_resposta = await tts_service.synthesize(resposta_texto)
    tts_time = (time.time() - tts_start) * 1000
    
    # Envia Ã¡udio via WebSocket
    if not await safe_send_bytes(websocket, audio_resposta):
        logger.warning("ConexÃ£o fechada antes de enviar Ã¡udio")
        return session_id
```

**Arquivo:** `backend/services/tts_service.py`

ServiÃ§o Piper TTS:
```python
class PiperTTSService:
    def __init__(self, ...):
        # Inicializa Piper TTS (Fase 2)
        if settings.tts_engine == "piper":
            self.piper_service = NewPiperTTSService(
                model_path=settings.tts_model_path,
                config_path=settings.tts_config_path,
                use_cuda=settings.tts_use_cuda
            )
    
    async def synthesize(self, texto: str) -> bytes:
        # Processa texto (normalizaÃ§Ã£o, pronÃºncia, SSML)
        texto_processado = texto
        if self.text_processor:
            texto_processado = self.text_processor.process(texto_processado)
        
        # Verifica cache
        if self.cache:
            cached_audio = self.cache.get(texto_processado)
            if cached_audio:
                return cached_audio
        
        # Sintetiza
        if self.piper_service and self.piper_service.is_ready():
            audio_bytes = await self.piper_service.synthesize(texto_processado)
        elif EdgeTTSAvailable:
            audio_bytes = await self._synthesize_edge_tts(texto_processado)
        else:
            audio_bytes = self._synthesize_mock(texto_processado)  # Fallback
        
        # Armazena no cache
        if self.cache:
            self.cache.set(texto_processado, audio_bytes)
        
        return audio_bytes  # â† WAV bytes
```

**ConfiguraÃ§Ã£o (settings.py):**
```python
tts_engine: str = "piper"  # "piper" ou "edge" (fallback)
tts_model_path: str = "models/tts/pt_BR-jeff-medium.onnx"
tts_config_path: Optional[str] = "models/tts/pt_BR-jeff-medium.onnx.json"
tts_use_cuda: bool = False  # CPU por padrÃ£o
```

**Formato de saÃ­da do TTS:**
- Formato: WAV
- Sample Rate: 22050 Hz (Piper padrÃ£o) ou 16000 Hz (edge-tts)
- Canais: 1 (mono)
- Bits por amostra: 16-bit PCM

---

### 6. Backend: Retorno de Ãudio

**Arquivo:** `backend/api/routes/websocket_utils.py`

Envio seguro de bytes:
```python
async def safe_send_bytes(websocket: WebSocket, data: bytes) -> bool:
    try:
        if websocket.client_state.name != "CONNECTED":
            logger.debug("ConexÃ£o WebSocket nÃ£o estÃ¡ mais conectada")
            return False
        
        await websocket.send_bytes(data)
        return True
    except (RuntimeError, ConnectionError) as e:
        logger.debug("ConexÃ£o WebSocket fechada durante envio de bytes")
        return False
```

**Fluxo de mensagens enviadas:**
1. `{"type": "processing", "stage": "transcribing"}` - InÃ­cio de transcriÃ§Ã£o
2. `{"type": "transcription", "text": "...", "confidence": 0.95}` - TranscriÃ§Ã£o completa
3. `{"type": "processing", "stage": "generating"}` - InÃ­cio de geraÃ§Ã£o
4. `{"type": "response", "text": "...", "tokens": 150}` - Resposta de texto
5. `{"type": "processing", "stage": "synthesizing"}` - InÃ­cio de sÃ­ntese
6. `[BINARY DATA]` - Bytes do Ã¡udio WAV
7. `{"type": "complete", "metrics": {...}}` - Processamento completo

---

### 7. Mobile: RecepÃ§Ã£o e ReproduÃ§Ã£o

**Arquivo:** `mobile_app/lib/services/api/websocket_client.dart`

Recebimento de mensagens:
```dart
_channel!.stream.listen(
  (data) {
    if (onMessage != null) {
      onMessage!(data);  // â† Chama MessageHandler.handleMessage()
    }
  },
);
```

**Arquivo:** `mobile_app/lib/services/api/message_handler.dart`

Processamento de mensagens:
```dart
void handleMessage(dynamic data) {
  if (data is Uint8List || data is List<int>) {
    // Dados binÃ¡rios (Ã¡udio)
    final audioBytes = data is Uint8List ? data : Uint8List.fromList(data);
    debugPrint('ğŸ”Š Ãudio recebido: ${audioBytes.length} bytes');
    if (onAudioReceived != null) {
      onAudioReceived!(audioBytes);  // â† Chama callback do ApiService
    }
    return;
  }
  
  if (data is String) {
    final json = jsonDecode(data);
    final type = json['type'] as String?;
    
    switch (type) {
      case 'transcription':
        // Atualiza mensagem do usuÃ¡rio com transcriÃ§Ã£o
        break;
      case 'response':
        // Adiciona mensagem de resposta do assistente
        break;
      case 'processing':
        // Atualiza status de processamento
        break;
      // ...
    }
  }
}
```

**Arquivo:** `mobile_app/lib/services/api_service.dart`

Callback de Ã¡udio:
```dart
ApiService() {
  _messageHandler.onAudioReceived = (audio) {
    if (onAudioReceived != null) {
      onAudioReceived!(audio);  // â† Callback configurado externamente
    }
  };
}
```

**Arquivo:** `mobile_app/lib/screens/home_screen.dart`

ConfiguraÃ§Ã£o do callback:
```dart
@override
void initState() {
  super.initState();
  final apiService = context.read<ApiService>();
  final audioService = context.read<AudioService>();
  
  // Configura callback para reproduzir Ã¡udio quando recebido
  apiService.onAudioReceived = (audioBytes) {
    audioService.playAudio(audioBytes);
  };
}
```

**Arquivo:** `mobile_app/lib/services/audio/audio_playback.dart`

ReproduÃ§Ã£o:
```dart
Future<void> playAudio(Uint8List audioBytes, {int maxRetries = 2}) async {
  // Valida tamanho mÃ­nimo (44 bytes = header WAV)
  if (audioBytes.length < 44) {
    throw Exception('Ãudio invÃ¡lido: muito pequeno');
  }
  
  // Salva em arquivo temporÃ¡rio
  final tempFile = File('$tempPath/audio_response_{timestamp}.wav');
  await tempFile.writeAsBytes(audioBytes);
  
  // Reproduz com just_audio
  await _player.setFilePath(tempFile.path);
  await _player.play();
  
  // Aguarda conclusÃ£o
  await completer.future.timeout(timeout);
  
  // Limpa arquivo temporÃ¡rio
  await tempFile.delete();
}
```

**Biblioteca:** `just_audio`
- Suporta WAV, MP3, OGG, FLAC
- Auto-detecta sample rate e canais do WAV
- Reproduz em formato nativo do dispositivo

---

## ConfiguraÃ§Ãµes de Ãudio

### Mobile (GravaÃ§Ã£o)

**Arquivo:** `mobile_app/lib/services/audio/audio_recording.dart`

```dart
RecordConfig(
  encoder: AudioEncoder.wav,    // Formato: WAV
  sampleRate: 16000,            // 16kHz (ideal para Whisper)
  numChannels: 1,               // Mono
)
```

### Backend (STT - Whisper)

**Arquivo:** `backend/config/settings.py`

```python
whisper_model: str = "large-v3"      # Modelo: large-v3 (melhor PT-BR)
whisper_device: str = "cpu"          # CPU ou cuda
whisper_compute_type: str = "int8"   # int8 (rÃ¡pido), float16 (balanceado), float32 (melhor qualidade)
```

**ParÃ¢metros de transcriÃ§Ã£o:**
- `beam_size`: 3 (otimizado para velocidade)
- `vad_filter`: Habilitado para Ã¡udios > 2s
- `language`: "pt" (portuguÃªs)

### Backend (TTS - Piper)

**Arquivo:** `backend/config/settings.py`

```python
tts_engine: str = "piper"                              # Engine: piper ou edge
tts_model_path: str = "models/tts/pt_BR-jeff-medium.onnx"
tts_config_path: str = "models/tts/pt_BR-jeff-medium.onnx.json"
tts_use_cuda: bool = False                            # CPU por padrÃ£o
tts_pronunciation_dict_path: str = "backend/data/tts_pronunciation_dict.json"
tts_enable_ssml: bool = True                          # SSML habilitado
tts_enable_numbers: bool = True                       # NormalizaÃ§Ã£o de nÃºmeros
tts_enable_dates: bool = True                         # NormalizaÃ§Ã£o de datas
```

**Formato de saÃ­da:**
- Sample Rate: 22050 Hz (Piper padrÃ£o) ou 16000 Hz (edge-tts)
- Formato: WAV 16-bit PCM
- Canais: 1 (mono)

### ValidaÃ§Ãµes

**Backend:** `backend/api/validators/audio_validator.py`

```python
MAX_AUDIO_SIZE = 10 * 1024 * 1024      # 10 MB mÃ¡ximo
MIN_AUDIO_SIZE = 100                    # 100 bytes mÃ­nimo
SUPPORTED_FORMATS = ["wav", "mp3", "ogg", "flac"]
MAX_DURATION_SECONDS = 300              # 5 minutos mÃ¡ximo
```

**Mobile:** `mobile_app/lib/utils/audio_validator.dart`

```dart
static const int minWavHeaderSize = 44;  // Header WAV mÃ­nimo
```

---

## Troubleshooting: Ãudio Enviado Mas Sem Resposta

### ğŸ” DiagnÃ³stico Passo a Passo

#### 1. Verificar se Ã¡udio estÃ¡ sendo enviado

**Mobile (logs):**
```dart
debugPrint('ğŸ“¤ Ãudio enviado: ${audioBytes.length} bytes');
```

**Backend (logs):**
```
ğŸ¤ Ãudio recebido de {client_ip}: {audio_size} bytes
ğŸµ Iniciando processamento de Ã¡udio: {len(audio_data)} bytes
```

**AÃ§Ã£o:** Verifique logs do mobile e backend. Se nÃ£o aparecer "Ãudio recebido", problema Ã© na conexÃ£o WebSocket.

#### 2. Verificar transcriÃ§Ã£o (STT)

**Backend (logs):**
```
ğŸ™ï¸ Iniciando transcriÃ§Ã£o de Ã¡udio...
âœ… TranscriÃ§Ã£o concluÃ­da: '...' (confianÃ§a: 0.95, segmentos: 1)
```

**Mensagem WebSocket enviada:**
```json
{"type": "transcription", "text": "...", "confidence": 0.95}
```

**Problemas comuns:**
- TranscriÃ§Ã£o vazia: Ãudio sem fala ou muito baixo
- ConfianÃ§a muito baixa (< 0.5): RuÃ­do excessivo ou modelo incorreto
- Erro no STT: Modelo Whisper nÃ£o carregado ou formato invÃ¡lido

**AÃ§Ã£o:** Verifique se `whisper_model` estÃ¡ correto e se modelo estÃ¡ disponÃ­vel.

#### 3. Verificar geraÃ§Ã£o de resposta (LLM)

**Backend (logs):**
```
ğŸ¤– Gerando resposta com LLM...
âœ… Resposta gerada: '...' (150 tokens)
```

**Mensagem WebSocket enviada:**
```json
{"type": "response", "text": "...", "tokens": 150}
```

**Problemas comuns:**
- LLM nÃ£o retorna resposta: Timeout, erro de conexÃ£o (Groq), ou modelo offline (Ollama)
- Resposta vazia ou "None": Erro no LLM service
- Resposta sanitizada ficou vazia: Sanitizer removeu todo o conteÃºdo

**AÃ§Ã£o:** Verifique:
- ConexÃ£o com Groq (API key vÃ¡lida)
- Ollama rodando (`ollama serve`)
- Modelo configurado corretamente

#### 4. Verificar sÃ­ntese de Ã¡udio (TTS)

**Backend (logs):**
```
ğŸ”Š Iniciando sÃ­ntese de voz...
âœ… Ãudio sintetizado: {len(audio_resposta)} bytes
```

**Mensagem WebSocket enviada:**
```
[BINARY DATA] - Bytes do Ã¡udio WAV
```

**Problemas comuns:**
- TTS retorna vazio: Modelo Piper nÃ£o carregado ou erro no edge-tts
- Ãudio muito pequeno: Erro na sÃ­ntese, retornando apenas header WAV
- Erro no TTS: Modelo nÃ£o encontrado ou caminho incorreto

**AÃ§Ã£o:** Verifique:
- Modelo Piper existe: `models/tts/pt_BR-jeff-medium.onnx`
- Config JSON existe: `models/tts/pt_BR-jeff-medium.onnx.json`
- edge-tts disponÃ­vel como fallback

#### 5. Verificar envio de Ã¡udio via WebSocket

**Backend (logs):**
```
ğŸ“¤ Ãudio enviado ao cliente
```

**CÃ³digo:** `backend/api/handlers/websocket_audio_processor.py:225`

```python
if not await safe_send_bytes(websocket, audio_resposta):
    logger.warning("ConexÃ£o fechada antes de enviar Ã¡udio")
    return session_id
```

**Problemas comuns:**
- ConexÃ£o fechada: Cliente desconectou antes de receber Ã¡udio
- Erro ao enviar: WebSocket em estado invÃ¡lido

**AÃ§Ã£o:** Verifique se conexÃ£o WebSocket ainda estÃ¡ ativa.

#### 6. Verificar recepÃ§Ã£o no Mobile

**Mobile (logs):**
```dart
debugPrint('ğŸ”Š Ãudio recebido: ${audioBytes.length} bytes');
```

**Problemas comuns:**
- Ãudio nÃ£o chega: WebSocket desconectado ou filtrado
- Ãudio vazio: Backend enviou dados vazios
- Callback nÃ£o configurado: `onAudioReceived` nÃ£o foi definido

**AÃ§Ã£o:** Verifique:
- Callback configurado em `home_screen.dart`
- WebSocket ainda conectado (`apiService.isConnected`)

#### 7. Verificar reproduÃ§Ã£o no Mobile

**Mobile (logs):**
```dart
debugPrint('ğŸ”Š Iniciando reproduÃ§Ã£o de Ã¡udio: ${audioBytes.length} bytes');
```

**Problemas comuns:**
- Ãudio muito pequeno: < 44 bytes (header WAV mÃ­nimo)
- Erro no just_audio: Formato invÃ¡lido ou arquivo corrompido
- PermissÃ£o de Ã¡udio negada: Android nÃ£o permite reproduÃ§Ã£o

**AÃ§Ã£o:** Verifique logs de erro do `AudioPlayback`.

---

### ğŸ› ï¸ Checklist de Troubleshooting

#### Backend

- [ ] Servidor rodando (`curl http://localhost:8000/health`)
- [ ] Whisper modelo carregado (logs: "Modelo Whisper carregado")
- [ ] LLM service inicializado (Groq key vÃ¡lida OU Ollama rodando)
- [ ] TTS service inicializado (Piper modelo existe OU edge-tts disponÃ­vel)
- [ ] WebSocket endpoint acessÃ­vel (`ws://localhost:8000/ws/listen`)
- [ ] Logs mostram "Ãudio recebido"
- [ ] Logs mostram "TranscriÃ§Ã£o concluÃ­da"
- [ ] Logs mostram "Resposta gerada"
- [ ] Logs mostram "Ãudio sintetizado"
- [ ] Logs mostram "Ãudio enviado ao cliente"

#### Mobile

- [ ] App conectado ao WebSocket (`apiService.isConnected == true`)
- [ ] PermissÃ£o de microfone concedida
- [ ] GravaÃ§Ã£o funciona (logs: "GravaÃ§Ã£o iniciada")
- [ ] Ãudio enviado (logs: "Ãudio enviado: X bytes")
- [ ] Callback `onAudioReceived` configurado
- [ ] Ãudio recebido (logs: "Ãudio recebido: X bytes")
- [ ] ReproduÃ§Ã£o inicia (logs: "Iniciando reproduÃ§Ã£o")
- [ ] PermissÃ£o de Ã¡udio no Android (manifest.xml)

#### WebSocket

- [ ] ConexÃ£o estabelecida (logs: "Conectado ao assistente")
- [ ] Mensagens de status recebidas (`processing`, `transcription`, `response`)
- [ ] Ãudio binÃ¡rio recebido (tipo `Uint8List`)
- [ ] ConexÃ£o nÃ£o fecha durante processamento

---

### ğŸ› Pontos CrÃ­ticos de Falha

#### 1. STT retorna texto vazio

**Sintoma:** Backend loga "TranscriÃ§Ã£o vazia"

**Causas possÃ­veis:**
- Ãudio sem fala detectada
- Ãudio muito curto (< 0.5s)
- RuÃ­do excessivo
- Modelo Whisper incorreto

**SoluÃ§Ã£o:**
- Verificar qualidade do Ã¡udio gravado
- Aumentar duraÃ§Ã£o mÃ­nima de gravaÃ§Ã£o
- Usar modelo Whisper maior (large-v3 â†’ melhor qualidade)

#### 2. LLM nÃ£o retorna resposta

**Sintoma:** Backend nÃ£o loga "Resposta gerada" OU resposta vazia

**Causas possÃ­veis:**
- Groq API key invÃ¡lida ou expirada
- Ollama nÃ£o estÃ¡ rodando
- Timeout do LLM
- Erro na chamada do LLM

**SoluÃ§Ã£o:**
- Verificar API key Groq
- Iniciar Ollama: `ollama serve`
- Aumentar timeout
- Verificar logs de erro do LLM service

#### 3. TTS retorna Ã¡udio vazio

**Sintoma:** Backend loga "Ãudio sintetizado: 0 bytes" ou muito pequeno

**Causas possÃ­veis:**
- Modelo Piper nÃ£o encontrado
- Erro no edge-tts
- Texto vazio apÃ³s sanitizaÃ§Ã£o

**SoluÃ§Ã£o:**
- Verificar caminho do modelo Piper
- Testar edge-tts manualmente
- Verificar resposta de texto antes do TTS

#### 4. Ãudio nÃ£o chega no Mobile

**Sintoma:** Mobile nÃ£o loga "Ãudio recebido"

**Causas possÃ­veis:**
- WebSocket desconectado antes de enviar Ã¡udio
- Erro ao enviar bytes (`safe_send_bytes` retorna False)
- Cliente nÃ£o estÃ¡ escutando mensagens binÃ¡rias

**SoluÃ§Ã£o:**
- Verificar se WebSocket ainda estÃ¡ conectado
- Verificar logs de erro do `safe_send_bytes`
- Testar recepÃ§Ã£o de mensagens JSON primeiro

#### 5. Ãudio recebido mas nÃ£o reproduz

**Sintoma:** Mobile loga "Ãudio recebido" mas nÃ£o toca

**Causas possÃ­veis:**
- Callback `onAudioReceived` nÃ£o configurado
- Erro no `AudioPlayback.playAudio()`
- PermissÃ£o de Ã¡udio negada (Android)
- Formato invÃ¡lido

**SoluÃ§Ã£o:**
- Verificar callback em `home_screen.dart`
- Verificar logs de erro do `AudioPlayback`
- Verificar permissÃµes no AndroidManifest.xml
- Validar formato do Ã¡udio recebido

---

### ğŸ“Š Logs para AnÃ¡lise

**Backend (Python - loguru):**
```
INFO: ğŸ¤ Ãudio recebido de 192.168.1.6: 12345 bytes
INFO: ğŸµ Iniciando processamento de Ã¡udio: 12345 bytes
INFO: ğŸ™ï¸ Iniciando transcriÃ§Ã£o de Ã¡udio...
INFO: âœ… TranscriÃ§Ã£o concluÃ­da: 'olÃ¡' (confianÃ§a: 0.95)
INFO: ğŸ¤– Gerando resposta com LLM...
INFO: âœ… Resposta gerada: 'OlÃ¡! Como posso ajudar?' (150 tokens)
INFO: ğŸ”Š Iniciando sÃ­ntese de voz...
INFO: âœ… Ãudio sintetizado: 54321 bytes
INFO: ğŸ“¤ Ãudio enviado ao cliente
```

**Mobile (Flutter - debugPrint):**
```dart
ğŸ“¤ Ãudio enviado: 12345 bytes
âœ… Conectado ao assistente
ğŸ“ TranscriÃ§Ã£o: "olÃ¡" (confianÃ§a: 0.95)
ğŸ¤– Resposta: "OlÃ¡! Como posso ajudar?" (150 tokens)
ğŸ”Š Ãudio recebido: 54321 bytes
ğŸ”Š Iniciando reproduÃ§Ã£o de Ã¡udio: 54321 bytes
âœ… ReproduÃ§Ã£o concluÃ­da
```

---

### ğŸ”§ Comandos Ãšteis

**Testar conexÃ£o WebSocket:**
```bash
# Backend
curl http://localhost:8000/health

# WebSocket (use wscat ou Postman)
wscat -c ws://localhost:8000/ws/listen
```

**Verificar modelo Whisper:**
```python
from backend.services.stt_service import WhisperSTTService
stt = WhisperSTTService()
print(stt.is_ready())  # True se modelo carregado
```

**Verificar modelo TTS:**
```python
from backend.services.tts_service import PiperTTSService
tts = PiperTTSService()
print(tts.is_ready())  # True se serviÃ§o disponÃ­vel
```

**Testar TTS manualmente:**
```python
audio_bytes = await tts.synthesize("OlÃ¡, teste")
print(f"Ãudio gerado: {len(audio_bytes)} bytes")
```

---

## ğŸ“ Notas Finais

- **Formato de Ã¡udio:** WAV Ã© o formato padrÃ£o em todo o pipeline
- **Sample rate:** 16kHz na gravaÃ§Ã£o, 22kHz na sÃ­ntese (Piper), compatÃ­vel entre si
- **Canais:** Mono (1 canal) em todo o pipeline
- **WebSocket:** Protocolo binÃ¡rio para Ã¡udio, JSON para mensagens de controle
- **Timeouts:** Configurar timeouts adequados para STT, LLM e TTS
- **Cache:** TTS tem cache para evitar re-sÃ­ntese de textos repetidos
- **Fallback:** edge-tts como fallback se Piper nÃ£o estiver disponÃ­vel

---

**Ãšltima atualizaÃ§Ã£o:** 2025-12-11
**VersÃ£o:** 1.0.0

