"""
Teste de simula√ß√£o de fallback Groq ‚Üí Ollama
Testa o c√≥digo de fallback sem precisar atingir rate limit real
"""
import sys
from pathlib import Path

# Adiciona backend ao path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from backend.services.llm_service import GroqLLMService, OllamaLLMService
from unittest.mock import Mock, patch, MagicMock
from loguru import logger


def test_fallback_code_structure():
    """Testa se o c√≥digo de fallback est√° implementado corretamente"""
    print("=" * 60)
    print("TESTE - Estrutura do C√≥digo de Fallback")
    print("=" * 60)
    
    # Verifica se o c√≥digo tem tratamento de rate limit
    with open("backend/services/llm_service.py", "r", encoding="utf-8") as f:
        code = f.read()
    
    checks = {
        "Rate limit detection": "Rate limit" in code or "rate_limit" in code or "429" in code,
        "Fallback to Ollama": "ollama_service" in code or "OllamaLLMService" in code,
        "Error handling": "RuntimeError" in code and "rate limit" in code.lower(),
        "Fallback activation log": "[Groq‚ÜíOllama]" in code or "Fallback ativado" in code,
    }
    
    print("\nVerifica√ß√µes de c√≥digo:")
    all_passed = True
    for check_name, passed in checks.items():
        status = "‚úÖ" if passed else "‚ùå"
        print(f"  {status} {check_name}")
        if not passed:
            all_passed = False
    
    if all_passed:
        print("\n‚úÖ Estrutura do c√≥digo de fallback est√° correta!")
    else:
        print("\n‚ö†Ô∏è  Algumas verifica√ß√µes falharam")
    
    return all_passed


def test_ollama_service_availability():
    """Testa se OllamaService pode ser instanciado"""
    print("\n" + "=" * 60)
    print("TESTE - Disponibilidade do OllamaService")
    print("=" * 60)
    
    try:
        # Tenta importar
        from backend.services.llm_service import OllamaLLMService
        
        # Tenta criar inst√¢ncia (sem conectar)
        service = OllamaLLMService(
            model="llama3.1:8b",
            host="http://localhost:11434",
            temperature=0.7,
            max_tokens=512
        )
        
        print("‚úÖ OllamaLLMService pode ser instanciado")
        
        # Verifica se tem m√©todo generate_response
        if hasattr(service, 'generate_response'):
            print("‚úÖ M√©todo generate_response dispon√≠vel")
            return True
        else:
            print("‚ùå M√©todo generate_response n√£o encontrado")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro ao testar OllamaService: {e}")
        return False


def test_groq_error_detection():
    """Testa detec√ß√£o de erros do Groq"""
    print("\n" + "=" * 60)
    print("TESTE - Detec√ß√£o de Erros do Groq")
    print("=" * 60)
    
    # Simula diferentes tipos de erro
    error_messages = [
        "Rate limit reached for model",
        "rate_limit_exceeded",
        "Error code: 429",
        "Rate limit",
    ]
    
    code = ""
    with open("backend/services/llm_service.py", "r", encoding="utf-8") as f:
        code = f.read()
    
    detected = []
    for error_msg in error_messages:
        if error_msg.lower() in code.lower():
            detected.append(error_msg)
            print(f"  ‚úÖ Detecta: '{error_msg}'")
        else:
            print(f"  ‚ö†Ô∏è  N√£o detecta explicitamente: '{error_msg}'")
    
    if len(detected) >= 2:
        print(f"\n‚úÖ Sistema detecta m√∫ltiplos formatos de erro de rate limit")
        return True
    else:
        print(f"\n‚ö†Ô∏è  Detec√ß√£o pode ser melhorada")
        return False


def test_fallback_imports():
    """Testa se os imports necess√°rios est√£o presentes"""
    print("\n" + "=" * 60)
    print("TESTE - Imports Necess√°rios")
    print("=" * 60)
    
    try:
        # Verifica imports no llm_service.py
        with open("backend/services/llm_service.py", "r", encoding="utf-8") as f:
            code = f.read()
        
        required_imports = {
            "ollama": "ollama" in code or "import ollama" in code,
            "OllamaLLMService": "OllamaLLMService" in code,
            "RuntimeError": "RuntimeError" in code,
        }
        
        all_imported = True
        for import_name, imported in required_imports.items():
            status = "‚úÖ" if imported else "‚ùå"
            print(f"  {status} {import_name}")
            if not imported:
                all_imported = False
        
        if all_imported:
            print("\n‚úÖ Todos os imports necess√°rios est√£o presentes")
            return True
        else:
            print("\n‚ö†Ô∏è  Alguns imports podem estar faltando")
            return False
            
    except Exception as e:
        print(f"‚ùå Erro ao verificar imports: {e}")
        return False


def main():
    """Executa todos os testes"""
    results = []
    
    results.append(("Estrutura do C√≥digo", test_fallback_code_structure()))
    results.append(("OllamaService Dispon√≠vel", test_ollama_service_availability()))
    results.append(("Detec√ß√£o de Erros", test_groq_error_detection()))
    results.append(("Imports Necess√°rios", test_fallback_imports()))
    
    # Resumo
    print("\n" + "=" * 60)
    print("RESUMO DOS TESTES")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "‚úÖ PASSOU" if result else "‚ö†Ô∏è  VERIFICAR"
        print(f"{status} - {name}")
    
    print(f"\nTotal: {passed}/{total} testes passaram")
    
    if passed == total:
        print("\nüéâ C√≥digo de fallback est√° implementado corretamente!")
        print("\nüí° Para testar o fallback em a√ß√£o:")
        print("   1. Aguarde o Groq atingir rate limit (ou simule)")
        print("   2. Verifique os logs do servidor para mensagens de fallback")
        print("   3. O sistema deve usar Ollama automaticamente")
    else:
        print("\n‚ö†Ô∏è  Alguns testes falharam - verifique o c√≥digo")


if __name__ == "__main__":
    main()

